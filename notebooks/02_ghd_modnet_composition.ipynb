{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of experimental band gap\n",
    "\n",
    "This notebooks applies MODNet on the matbench experimental band gap data. It is a good example on how MODNet can be used for a composition only task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 17:30:48.168214: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-21 17:30:48.218996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-21 17:30:48.219055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-21 17:30:48.220618: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-21 17:30:48.228330: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 17:30:49.297319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/root/miniconda3/envs/modnetori/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matminer.datasets import load_dataset\n",
    "from modnet.models import MODNetModel\n",
    "from modnet.preprocessing import MODData\n",
    "import matplotlib.pyplot as plt \n",
    "from pymatgen.core import Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset import:\n",
    "The matbench_expt_gap dataset contains measured band gaps for 4604 compositions of inorganic semiconductors from Zhuo et al., JPCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>composition</th>\n",
       "      <th>gap expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ag, Au, S)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Ag, W, Br)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ag, Ge, Pb, S)</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Ag, Ge, Pb, Se)</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Ag, B, Br)</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        composition  gap expt\n",
       "0       (Ag, Au, S)      0.00\n",
       "1       (Ag, W, Br)      0.00\n",
       "2   (Ag, Ge, Pb, S)      1.83\n",
       "3  (Ag, Ge, Pb, Se)      1.51\n",
       "4       (Ag, B, Br)      0.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"matbench_expt_gap\")\n",
    "df[\"composition\"] = df[\"composition\"].map(Composition) # maps composition to a pymatgen composition object\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.975951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.445034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gap expt\n",
       "count  4604.000000\n",
       "mean      0.975951\n",
       "std       1.445034\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.812500\n",
       "max      11.700000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa613b8fe50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.hist(df.where(df[\"gap expt\"] == 0)[\"gap expt\"], bins=1, density=False, label=\"Zero band gap\")\n",
    "ax.hist(df.where(df[\"gap expt\"] > 0)[\"gap expt\"], bins=11, density=False, label=\"Non-zero band gap\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xlabel(\"Band gap (eV)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 17:31:33,801 - modnet - INFO - Loaded CompositionOnlyMatminer2023Featurizer featurizer.\n"
     ]
    }
   ],
   "source": [
    "# This instantiates the MODData\n",
    "data = MODData(\n",
    "    materials=df[\"composition\"], # you can provide composition objects to MODData\n",
    "    targets=df[\"gap expt\"], \n",
    "    target_names=[\"gap_expt_eV\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 17:32:06,422 - modnet - INFO - Computing features, this can take time...\n",
      "2024-01-21 17:32:06,424 - modnet - INFO - Applying composition featurizers...\n",
      "2024-01-21 17:32:06,431 - modnet - INFO - Applying featurizers (AtomicOrbitals(), AtomicPackingEfficiency(), BandCenter(), ElementFraction(), ElementProperty(data_source=<matminer.utils.data.MagpieData object at 0x7fa6121fe790>,\n",
      "                features=['Number', 'MendeleevNumber', 'AtomicWeight',\n",
      "                          'MeltingT', 'Column', 'Row', 'CovalentRadius',\n",
      "                          'Electronegativity', 'NsValence', 'NpValence',\n",
      "                          'NdValence', 'NfValence', 'NValence', 'NsUnfilled',\n",
      "                          'NpUnfilled', 'NdUnfilled', 'NfUnfilled', 'NUnfilled',\n",
      "                          'GSvolume_pa', 'GSbandgap', 'GSmagmom',\n",
      "                          'SpaceGroupNumber'],\n",
      "                stats=['minimum', 'maximum', 'range', 'mean', 'avg_dev',\n",
      "                       'mode']), IonProperty(), Miedema(ss_types=['min'], struct_types=['inter', 'amor', 'ss']), Stoichiometry(), TMetalFraction(), ValenceOrbital(), YangSolidSolution()) to column 'composition'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultipleFeaturizer: 100%|██████████| 4604/4604 [30:15<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 18:02:38,002 - modnet - INFO - Data has successfully been featurized!\n"
     ]
    }
   ],
   "source": [
    "# Featurization of the moddata\n",
    "# It will automatically apply composition only featurizers\n",
    "data.featurize(n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 18:02:38,027 - modnet - INFO - Data successfully saved as out/matbench_expt_gap_nofeatureselection.moddata!\n"
     ]
    }
   ],
   "source": [
    "data.save('out/matbench_expt_gap_nofeatureselection.moddata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(range(100), test_size=0.1, random_state=1234)\n",
    "train, test = data.split(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-21 18:02:38,048 - modnet - INFO - Loading cross NMI from 'Features_cross' file.\n",
      "2024-01-21 18:02:38,079 - modnet - WARNING - Feature mismatch between precomputed `Features_cross` and `df_featurized`. Missing columns: {'Miedema|Miedema_deltaH_amor', 'Miedema|Miedema_deltaH_ss_min'}\n",
      "2024-01-21 18:02:38,082 - modnet - INFO - Starting target 1/1: gap_expt_eV ...\n",
      "2024-01-21 18:02:38,083 - modnet - INFO - Computing mutual information between features and target...\n",
      "2024-01-21 18:02:44,721 - modnet - INFO - Computing optimal features...\n",
      "2024-01-21 18:02:47,405 - modnet - INFO - Selected 50/242 features...\n",
      "2024-01-21 18:02:49,535 - modnet - INFO - Selected 100/242 features...\n",
      "2024-01-21 18:02:51,053 - modnet - INFO - Selected 150/242 features...\n",
      "2024-01-21 18:02:51,955 - modnet - INFO - Selected 200/242 features...\n",
      "2024-01-21 18:02:52,224 - modnet - INFO - Done with target 1/1: gap_expt_eV.\n",
      "2024-01-21 18:02:52,225 - modnet - INFO - Merging all features...\n",
      "2024-01-21 18:02:52,225 - modnet - INFO - Done.\n"
     ]
    }
   ],
   "source": [
    "# train.feature_selection(n=-1)\n",
    "# if you want to use precomputed cross_nmi of the MP. This saves time :\n",
    "data.feature_selection(n=-1, use_precomputed_cross_nmi=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 18:02:52.262332: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-21 18:02:52.295009: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = MODNetModel([[['gap_expt_eV']]],\n",
    "                    weights={'gap_expt_eV':1},\n",
    "                    num_neurons = [[256], [128], [16], [16]],\n",
    "                    n_feat = 150,\n",
    "                    act =  \"elu\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.1403 - mae: 1.1403 - val_loss: 1.1806 - val_mae: 1.1806\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9577 - mae: 0.9577 - val_loss: 0.8098 - val_mae: 0.8098\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8267 - mae: 0.8267 - val_loss: 0.5956 - val_mae: 0.5956\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7825 - mae: 0.7825 - val_loss: 0.5075 - val_mae: 0.5075\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7321 - mae: 0.7321 - val_loss: 0.4663 - val_mae: 0.4663\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6460 - mae: 0.6460 - val_loss: 0.4526 - val_mae: 0.4526\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6106 - mae: 0.6106 - val_loss: 0.4397 - val_mae: 0.4397\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6307 - mae: 0.6307 - val_loss: 0.4066 - val_mae: 0.4066\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6335 - mae: 0.6335 - val_loss: 0.3399 - val_mae: 0.3399\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6024 - mae: 0.6024 - val_loss: 0.3611 - val_mae: 0.3611\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5935 - mae: 0.5935 - val_loss: 0.3748 - val_mae: 0.3748\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6024 - mae: 0.6024 - val_loss: 0.3613 - val_mae: 0.3613\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5872 - mae: 0.5872 - val_loss: 0.3380 - val_mae: 0.3380\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5521 - mae: 0.5521 - val_loss: 0.3084 - val_mae: 0.3084\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5124 - mae: 0.5124 - val_loss: 0.3470 - val_mae: 0.3470\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5071 - mae: 0.5071 - val_loss: 0.3885 - val_mae: 0.3885\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5099 - mae: 0.5099 - val_loss: 0.3749 - val_mae: 0.3749\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5000 - mae: 0.5000 - val_loss: 0.3229 - val_mae: 0.3229\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4938 - mae: 0.4938 - val_loss: 0.2932 - val_mae: 0.2932\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4896 - mae: 0.4896 - val_loss: 0.2916 - val_mae: 0.2916\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4728 - mae: 0.4728 - val_loss: 0.3292 - val_mae: 0.3292\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4632 - mae: 0.4632 - val_loss: 0.3369 - val_mae: 0.3369\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4573 - mae: 0.4573 - val_loss: 0.3149 - val_mae: 0.3149\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4447 - mae: 0.4447 - val_loss: 0.3194 - val_mae: 0.3194\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4426 - mae: 0.4426 - val_loss: 0.3206 - val_mae: 0.3206\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4319 - mae: 0.4319 - val_loss: 0.3186 - val_mae: 0.3186\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4270 - mae: 0.4270 - val_loss: 0.3013 - val_mae: 0.3013\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4189 - mae: 0.4189 - val_loss: 0.2897 - val_mae: 0.2897\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4151 - mae: 0.4151 - val_loss: 0.3195 - val_mae: 0.3195\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4068 - mae: 0.4068 - val_loss: 0.3268 - val_mae: 0.3268\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4006 - mae: 0.4006 - val_loss: 0.3174 - val_mae: 0.3174\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3943 - mae: 0.3943 - val_loss: 0.2972 - val_mae: 0.2972\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3893 - mae: 0.3893 - val_loss: 0.2909 - val_mae: 0.2909\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4032 - mae: 0.4032 - val_loss: 0.3035 - val_mae: 0.3035\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3910 - mae: 0.3910 - val_loss: 0.3518 - val_mae: 0.3518\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4157 - mae: 0.4157 - val_loss: 0.3268 - val_mae: 0.3268\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3787 - mae: 0.3787 - val_loss: 0.2772 - val_mae: 0.2772\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4021 - mae: 0.4021 - val_loss: 0.2739 - val_mae: 0.2739\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3857 - mae: 0.3857 - val_loss: 0.3349 - val_mae: 0.3349\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3699 - mae: 0.3699 - val_loss: 0.3300 - val_mae: 0.3300\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3686 - mae: 0.3686 - val_loss: 0.2848 - val_mae: 0.2848\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3618 - mae: 0.3618 - val_loss: 0.2708 - val_mae: 0.2708\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3633 - mae: 0.3633 - val_loss: 0.2664 - val_mae: 0.2664\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3563 - mae: 0.3563 - val_loss: 0.2749 - val_mae: 0.2749\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3504 - mae: 0.3504 - val_loss: 0.3002 - val_mae: 0.3002\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3551 - mae: 0.3551 - val_loss: 0.2617 - val_mae: 0.2617\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3462 - mae: 0.3462 - val_loss: 0.2476 - val_mae: 0.2476\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3529 - mae: 0.3529 - val_loss: 0.2612 - val_mae: 0.2612\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3468 - mae: 0.3468 - val_loss: 0.2711 - val_mae: 0.2711\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3432 - mae: 0.3432 - val_loss: 0.2457 - val_mae: 0.2457\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3377 - mae: 0.3377 - val_loss: 0.2663 - val_mae: 0.2663\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3370 - mae: 0.3370 - val_loss: 0.2847 - val_mae: 0.2847\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3323 - mae: 0.3323 - val_loss: 0.2692 - val_mae: 0.2692\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3240 - mae: 0.3240 - val_loss: 0.2706 - val_mae: 0.2706\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3310 - mae: 0.3310 - val_loss: 0.2606 - val_mae: 0.2606\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3298 - mae: 0.3298 - val_loss: 0.2561 - val_mae: 0.2561\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3256 - mae: 0.3256 - val_loss: 0.2406 - val_mae: 0.2406\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3221 - mae: 0.3221 - val_loss: 0.2469 - val_mae: 0.2469\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3148 - mae: 0.3148 - val_loss: 0.2829 - val_mae: 0.2829\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3173 - mae: 0.3173 - val_loss: 0.2982 - val_mae: 0.2982\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3278 - mae: 0.3278 - val_loss: 0.2672 - val_mae: 0.2672\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3147 - mae: 0.3147 - val_loss: 0.2564 - val_mae: 0.2564\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3023 - mae: 0.3023 - val_loss: 0.2661 - val_mae: 0.2661\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3096 - mae: 0.3096 - val_loss: 0.2566 - val_mae: 0.2566\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3074 - mae: 0.3074 - val_loss: 0.2392 - val_mae: 0.2392\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3029 - mae: 0.3029 - val_loss: 0.2391 - val_mae: 0.2391\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2964 - mae: 0.2964 - val_loss: 0.2274 - val_mae: 0.2274\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2932 - mae: 0.2932 - val_loss: 0.2589 - val_mae: 0.2589\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3011 - mae: 0.3011 - val_loss: 0.2981 - val_mae: 0.2981\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2972 - mae: 0.2972 - val_loss: 0.2714 - val_mae: 0.2714\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2911 - mae: 0.2911 - val_loss: 0.2824 - val_mae: 0.2824\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2844 - mae: 0.2844 - val_loss: 0.2689 - val_mae: 0.2689\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2867 - mae: 0.2867 - val_loss: 0.2735 - val_mae: 0.2735\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2851 - mae: 0.2851 - val_loss: 0.2878 - val_mae: 0.2878\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2804 - mae: 0.2804 - val_loss: 0.2580 - val_mae: 0.2580\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2808 - mae: 0.2808 - val_loss: 0.2448 - val_mae: 0.2448\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2887 - mae: 0.2887 - val_loss: 0.2720 - val_mae: 0.2720\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2816 - mae: 0.2816 - val_loss: 0.2942 - val_mae: 0.2942\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2792 - mae: 0.2792 - val_loss: 0.2699 - val_mae: 0.2699\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2739 - mae: 0.2739 - val_loss: 0.2697 - val_mae: 0.2697\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2687 - mae: 0.2687 - val_loss: 0.3203 - val_mae: 0.3203\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2759 - mae: 0.2759 - val_loss: 0.2798 - val_mae: 0.2798\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2658 - mae: 0.2658 - val_loss: 0.2865 - val_mae: 0.2865\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2585 - mae: 0.2585 - val_loss: 0.3228 - val_mae: 0.3228\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2633 - mae: 0.2633 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2666 - mae: 0.2666 - val_loss: 0.3036 - val_mae: 0.3036\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2562 - mae: 0.2562 - val_loss: 0.3094 - val_mae: 0.3094\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2571 - mae: 0.2571 - val_loss: 0.2702 - val_mae: 0.2702\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2718 - mae: 0.2718 - val_loss: 0.2917 - val_mae: 0.2917\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2505 - mae: 0.2505 - val_loss: 0.2882 - val_mae: 0.2882\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2457 - mae: 0.2457 - val_loss: 0.3332 - val_mae: 0.3332\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2543 - mae: 0.2543 - val_loss: 0.3210 - val_mae: 0.3210\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2558 - mae: 0.2558 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2489 - mae: 0.2489 - val_loss: 0.3592 - val_mae: 0.3592\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2620 - mae: 0.2620 - val_loss: 0.3163 - val_mae: 0.3163\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2490 - mae: 0.2490 - val_loss: 0.2647 - val_mae: 0.2647\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2740 - mae: 0.2740 - val_loss: 0.3148 - val_mae: 0.3148\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2389 - mae: 0.2389 - val_loss: 0.3308 - val_mae: 0.3308\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2458 - mae: 0.2458 - val_loss: 0.3030 - val_mae: 0.3030\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2369 - mae: 0.2369 - val_loss: 0.3392 - val_mae: 0.3392\n"
     ]
    }
   ],
   "source": [
    "model.fit(train,\n",
    "          val_fraction = 0.1,\n",
    "          lr = 0.0002,\n",
    "          batch_size = 64,\n",
    "          loss = 'mae',\n",
    "          epochs = 100,\n",
    "          verbose = 1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pred\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/modnetori/lib/python3.9/site-packages/modnet/models/vanilla.py:713\u001b[0m, in \u001b[0;36mMODNetModel.predict\u001b[0;34m(self, test_data, return_prob)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the target values for the passed MODData.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# prevents Nan predictions if some features are inf\u001b[39;00m\n\u001b[1;32m    711\u001b[0m x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    712\u001b[0m     test_data\u001b[38;5;241m.\u001b[39mget_featurized_df()\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan)[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimal_descriptors\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_feat\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    715\u001b[0m )\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Scale and impute input features:\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_impute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test)\n",
    "pred.head()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gap_expt_eV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id40</th>\n",
       "      <td>-0.508559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id35</th>\n",
       "      <td>2.871215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id81</th>\n",
       "      <td>-0.570688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id61</th>\n",
       "      <td>1.950733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id98</th>\n",
       "      <td>2.004308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gap_expt_eV\n",
       "id40    -0.508559\n",
       "id35     2.871215\n",
       "id81    -0.570688\n",
       "id61     1.950733\n",
       "id98     2.004308"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = np.absolute(pred.values-test.df_targets.values).mean()\n",
    "print(f'mae: {mae_test}')\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.3859002037048341\n"
     ]
    }
   ],
   "source": [
    "mae_test = np.absolute(pred.values-test.df_targets.values).mean()\n",
    "print(f'mae: {mae_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modnetori",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
